Deep RL 첫 걸음
7.1 함수를 활용한 근사
연속적인 상태 공간 : 상태의 값이 바둑이나 체스처럼 이산적으로 딱 떨어지는 것이 아니라 실수 범위 내에서 연속적인 값을 가지는 것
----> 상태 공간이 연속적이면 테이블을 만들기 불가능하다. (할 수 있다해도 굉장히 많은 시간이 필요하다.)

테이블 기반 방법론에서는 각각의 데이터 (s,a,r,s')가 그에 해당하는 딱 한 칸의 값만 업데이트하며, 주변의 다른 칸의 값에는 전혀 영향을 주지 않는다.
따라서 모든 칸을 업데이트하려면 모든 칸을 다 방문해야 한다. (필요한 경험의 숫자가 너무 크다.) ---> 다른 접근법이 필요 : 함수

새로운 접근법 : 함수
- 테이블 대신 함수에 상태 s와 그에 해당하는 밸류 v(s) 혹은 q(s,a)를 저장
- f(x) = ax + b ------> (100,1) (200,-10) -----> f(s0) = f(100) = 1, f(s1) = f(200) = -10
- 함수에다가 데이터를 새겨넣는 과정의 본질 ---> f는 상태 값을 input을 받아 v(s)의 값을 내놓는 함수가 되니, f가 곧 가치 함수이다
------> 실제 가치 함수의 근사 함수이다!!!!!!!!!!!
- 점이 2개일 때는 두점을 지나는 직선이 곧 함수였는데, 여러개가 된다면 직선을 그릴 수 없다.
------> 대신 점 여러 개를 가장 "가깝게" 지나가는 선을 그릴 수 있다. 최소제곱법을 사용할 것이다.

최소제곱법(least squares)
- (오차의 제곱의 합)을 최소화하는 a와 b를 찾는 방법론
- 데이터의 개수와 무관하게 표현한다면 각 오차의 제곱 합을 평균내고, MSE(Mean Squared Error)를 최소화하는 것이라고 볼 수 있다.

* 1. 함수에 저장하고, 함수의 곡선이 데이터에 가깝게 지나가도록 피팅합니다.
* 2. 피팅을 잘하기 위해서는 함수가 가지고 있는 파라미터들을 수정해야 한다.
* 3. 파라미터의 값(a, b)을 구하는 법으로는 MSE를 최소화하는 최소 제곱법을 배웠다

여기서 함수 f는 어떻게 정해야 할까????
====================================================================================================
함수의 복잡도에 따른 차이

함수의 용도 : 상태 s와 밸류 v(s)의 쌍을 기록해 놓는 용도로 함수를 사용
함수 f의 형태는 마음대로 정할 수 있다.
다항 함수
------> 1차 함수에서 n차 함수로 차수가 점점 올라갈수록 함수는 더 유연해지고, 더 복잡한 데이터에도 피팅을 할 수 있게 된다.
함수에 피팅한다.
- 함수에 데이터를 기록한다.
- 테이터 점들을 가장 가깝게 지나도록 함수를 그려본다.
- 함수 f의 파라미터 (a0~an)의 값을 찾는다.
- 함수 f를 학습한다. 
-----> 유연한 함수를 사용할 경우 데이터에 더 가깝게 지나고 에러가 줄어든다 

무조건 차수가 높은 함수가 데이터를 기록하는 데에 유리한가??????? 
- 데이터에는 노이즈가 섞여 있기 때문에 그렇지 않다.
- 노이즈 : 측정 또는 수집 과정에서 발생하는 불확실성으로 인해 발생하는 오차 
- 해결방법 : 데이터 평활화, 정규화, 데이터 측정 또는 수집 단계에서 노이즈를 줄이는 필터링 기술을 사용
- 평활화 : 데이터에서 노이즈를 제거하고 추세를 파악하기 위해 사용되는 기법
- 정규화 : 데이터의 범위를 일정한 범위로 조정하는 방법

강화학습에서 어떤 상태의 밸류는 그 상태로부터 에피소드가 끝날 때까지 얻는 리턴의 기댓값이다.
하지만 에이전트가 경험하는 각각의 에피소드는 비록 동일한 상태 s에서 출발하였다고 하더라도 서로 다른 리턴을 얻는다.
각각의 데이터 자체로만은 "틀린 값"이다. 그 샘플이 충분히 모였을 때의 평균이 실제 정답에 가까워질 수 있다.
==================================================================================================
오버 피팅과 언더 피팅

오버 피팅 : f를 정할 때, 너무 유연한 함수를 사용하여서 f가 노이즈에 피팅해 버리는 것
언더 피팅 : 실제 모델을 담기에 함수 f의 유연성이 부족하여 주어진 데이터와의 에러가 큰 상황
==================================================================================================
함수의 장점 : 일반화

가치 함수 v(s)를 저장해 두려면 상태마다 칸이 하나씩 있어야 한다
액션-가치 함수 q(s,a)를 저장해 두려면 (상태의 개수 x 액션의 개수) 만큼의 칸이 필요하다.
----> 함수 등장의 이유

실제 가치 함수 v(s)를 모사하는 함수 f를 학습시키는 것
예) 몬테카를로 방법을 사용한다면 각 상태 s와 그에 따른 리턴을 모아서 f를 학습시킬 수 있다.
* 왜 함수를 사용하면 저장 공간이 덜 필요할까???????????
- MDP에 존재하는 모든 상태별 가치를 학습하려면 모든 상태별 값들을 저장해야 하지 않나?????
- 다 경험해보지 못하더라도 몇개만 보고도 이와 비슷한 것을 짐작하는 것이다.

* 테이블 기반 방법론에 새로운 상태가 방문하게 되면, 테이블의 해당 칸은 비어있으므로 어떤 밸류를 갖게 될지 전혀 모른다.
- 하지만 함수 f를 학습했고, 함수는 일반화에 뛰어나다. 이미 경험한 데이터들을 바탕으로 경험하지 않은 데이터의 아웃풋이 어떻게 될지 예상해볼 수 있다.
- f가 잘 학습했다면 처음 보는 데이터에 대해서도 에러가 작은 값을 리턴할 것이다. (모든 상태 s에 대해 별도의 저장 공간이 필요하지 않다.)

하지만 함수가 만능이 아니다. 왜??? 
- 이미 가봤던 상태 중에 그와 비슷한 상태의 가치를 이용해 추측하는 것이기 때문에 아예 처음 보는 종류의 상태에 대해서는 아무리 학습을 잘 해도 그 값을 예측하기는 어렵다.
-------------------->>>>> 그래서 어떤 함수를 사용해야 할까요???? 인공 신경망이다.